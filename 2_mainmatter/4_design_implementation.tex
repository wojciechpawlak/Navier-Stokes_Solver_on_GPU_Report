\chapter{Design and Implementation}

\section{Design}
The design of the code is based on the implementation by Griebel et al. that is presented in their book\cite{griebel1998numerical}. Description of most of the functions is featured in the book, so here only the functions that were changed will be described.

To allow for computations on boundaries, ghost cells need to be allocated.


 Necessary changes had to be introduced to allow it to work with GPU. First of all, the OpenCL platform needs to instantiated and 

The most common form for a stream to take in GPGPU is a 2D grid because this fits naturally with the rendering model built into GPUs.

A set of kernels

Modularity

All code should be executed on GPU for valid comparison. 

justify changes you make
in the algorithm if you try to increase parallelism.


\section{Implementation}

\subsection{Developing with OpenCL}
A simplest standard OpenCL pipeline would consist of following steps:

\begin{enumerate}
\item 
\item
\end{enumerate}
find platform
find device
create context and queue
build program
write device buffers
execute kernel in range
read device buffers



Code in project is based on structure from Griebels code\cite{griebel1998numerical}. Least as possible was changed in structure as to keep it comparable with the original code.

Code is written in C and OpenCL C.

Two-dimensional arrays in original 
One-dimensional arrays for OpenCL code. 1D arrays cannot be passed to OpenCL kernels.

Worksize

Implementation consists of sets of kernels as 

Griebels code intrinsics: Memory allocation

Code is portable and works under both on Windows and Unix platforms. Tested on Windows 7 and Linux clusters. Compilers used are nvcc and Visual Studio on Windows and gcc on Linux.

Table Computer specs.

%\subsection{Description of functions}

Table

\subsection{Functions}
Map

The map operation simply applies the given function (the kernel) to every element in the stream. A simple example is multiplying each value in the stream by a constant (increasing the brightness of an image). The map operation is simple to implement on the GPU. The programmer generates a fragment for each pixel on screen and applies a fragment program to each one. The result stream of the same size is stored in the output buffer.


Reduce

Some computations require calculating a smaller stream (possibly a stream of only 1 element) from a larger stream. This is called a reduction of the stream. Generally a reduction can be accomplished in multiple steps. The results from the prior step are used as the input for the current step and the range over which the operation is applied is reduced until only one stream element remains.

Gather

The fragment processor is able to read textures in a random access fashion, so it can gather information from any grid cell, or multiple grid cells, as desired.

\subsection{Stencil computation}


\subsection{Benchmarking code}
Code is timed with standard library time.h clock function.
No OpenCL timer code because on CPU. Code timed with buffer allocation and memory access and without.

\subsection{Visualisation code}
Matlab scripts to visualise code. Tests.

\subsection{Naive kernels}
Straightforward port of functions to kernels. Getting rid of for loops. Ensuring that boundaries are not crossed.


\subsection{Shared memory kernels}

THis does not require changin the current algorithms

auto-tune each kernel by finding optimal
configurations for threads/Blocks (i.e. Work items/groups) 

 This can be done by brute-forces tests and simple timing
experiments and would be interesting.

\subsection{Development}
Production code should, however, systematically check the error code returned by each API call and check for failures in kernel launches (or groups of kernel launches in the case of concurrent kernels) 