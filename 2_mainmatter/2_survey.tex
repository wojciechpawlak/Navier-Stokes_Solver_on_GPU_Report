\chapter{Survey of GPU programming}

General-purpose computing on graphics processing units 	Diffusion of non standardized methods 	CPU for a few specialized uses 	Order of magnitude faster processing of parallelizable algorithms

For the exploitation of the high performance of GPUs, codes must express sufficient fine-grained parallelism, minimize GPU–CPU data transfer, and achieve coalesced memory access. One option for writing the GPU code is to do so directly in CUDA [1] or OpenCL [27]. For a large Fortran code written well before the existence of GPUs, this entails a massive effort to rewrite, debug, and maintain a separate branch of the code. An alternative to performing such a monolithic code rewrite is to follow the ‘accelerator design’, as so called by Cohen and Molemaker, of porting bottleneck loops or subroutines in isolation, with memory transfer calls made just before and after these bottleneck loops or subroutines. Although this allows for the possibility of an incremental porting effort, it suffers the drawback of introducing the crippling bottleneck of a large amount of data transfer across the system bus, which has at least an order of magnitude lower bandwidth than that of the internal GPU memory, and thus severely restricts the possible gain in performance when porting

Heterogeneous: Developers leverage AMD GPUs and CPUs for optimal application performance and user experience

Industry Standards:OpenCL™ and DirectCompute11enable cross-platform development

High performance: Massively parallel, programmable GPU architecture enables superior performance and power efficiency

With OpenCL

Leverage CPUs and GPUs to accelerate parallel computation
Get dramatic speedups for computationally intensiveapplications
Write accelerated portablecode across different devices and architectures


AMD APP Acceleration 


AMD is still pushing its OpenCL strategy for GPU computing. 

From NVIDIA's perspective, the overriding goal is to bring GPU computing into the post-CUDA age.  CUDA C and Fortran are the most widely used programming languages for GPU programming today, but the underlying technology is proprietary to NVIDIA and offers a relatively low-level software model of GPU computing. As a result, the use of CUDA today tends to be restricted to computer science types, rather than the average programmer or researcher.

\hyperref{}{http://developer.amd.com/sdks/AMDAPPSDK/samples/showcase/Pages/default.aspx}
\hyperref{}{http://developer.amd.com/archive/AppShowcaseArchive/Pages/default.aspx}

Can write in C++ too.

Ports to Java (JavaCL) and Python (PyOpenCL).


Adopters: \hyperref{}{http://www.khronos.org/conformance/adopters/adopter-companies}
\hyperref{}{http://www.khronos.org/conformance/adopters/conformant-companies}

\subsection{Automation of porting to GPU process}

\hyperref[AMD]{http://stackoverflow.com/questions/1126989/what-future-does-the-gpu-have-in-computing}


\section{OpenCL}

OpenCL (Open Computing Language) is an open
standard defined by Khronos Group [16]. In contrast
to the CUDA library supported mainly by NVIDIA
it is a vendor-independent framework that enables
the programmer to develop software that can be executed
on heterogeneous platforms consisting of CPUs,
GPUs and potentially other processing units like FPGAs.

22Kernel
Basic unit of executable code -similar to a C function
Data-parallel or task-parallelProgram
Collection of kernels and other functions
Analogous to a dynamic libraryApplications queue kernel execution instances
Queued in-order
Executed in-order or out-of-order

Pipeline - table:
find platform
find device
create context and queue
build program
write device buffers
execute kernel in range
read device buffers

\subsection{Developing OpenCL Code}
Most of the development was done on Intel Processor and NVIDIA Geforce Card on Windows Platform. Microsoft Visual Studio 2010 IDE was used for development.

The largest problem during GPU programming is lack of debugging options. The choice of debugger is dependant on the platform used. Some combinations will then be not supported. It was the case during the development process for this project as NVIDIA card was combined with OpenCL technology.  Two working options for debugging found: NVIDIA Nsight (currently in version 4.2) and AMD gDEBugger (currently in version 6.2).

First supports CUDA code only. The tool is an application in a client-server architecture.  The Visual Studio Plugin serves as a client to the Monitor client process run on the machine. This allows for remote access to GPUs. Moreover, the breakpoints can be set inside the CUDA kernel code and the current state of local variables, warps and working items will be presented. This valuable data is available through a set of info windows. Warps can be observed. Tool does not work with OpenCL code though. It is not possible to set breakpoints in OpenCL code. Tool is distributed as a plugin to Visual Studio 2010.

The second works only with OpenCL code on the AMD devices. Stops on breakpoints on host. Can be asked to stop on specific OpenCL functions. Offers function call history an function properties. There is also an explorer where OpenCL constructs are presented in a tree structure.

In addition, there is an Intel SDK that allows for checking if the code is ready to be run on Intel platform like CPU or new 3rd generation processors with hardware graphics embedded. An offline compiler is used tor these purposes. 

\subsection{Profiling OpenCL Code}

Nsight Profiler

AMD gDEBugger

\subsection{Differences to CUDA}

\hyperref{}{http://www.hpcwire.com/hpcwire/2012-02-28/opencl_gains_ground_on_cuda.html}

\section{Previous research}



\section{Recent developments in CUDA and OpenCL}
\subsection{OpenCL}

What applications use OpenCL GPU-acceleration?
OpenCL in Photoshop CS6
WinZip 16.5

OpenCL Studio

\hyperref[OpenCLStudio]{http://www.youtube.com/user/OpenCLStudio}

\subsection{CUDA}

4.2

In Decemeber, NVIDIA made its nvcc compiler open.
\hyperref{}{http://www.hpcwire.com/hpcwire/2012-01-26/nvidia_releases_upgraded_cuda_compiler,_visual_profiler,_and_npp_library.html}

\subsection{Other Technologies}
\subsubsection{C++ AMP (C++ Accelerated Massive Parallelism)}

\hyperref[C++ AMP MSDN]{http://msdn.microsoft.com/en-us/library/hh265137}

\subsubsection{OpenACC}
Directives like OpenMP for multicore CPU programming

announcement of a new directives-based parallel programming standard for accelerators.  Called OpenACC, the open standard is intended to bring GPU computing into the realm of the average programmer, while making the resulting code portable across other accelerators and even multicore CPUs
\hyperref[OpenACC]{http://openacc.org/}
\hyperref{OpenACC}{http://www.hpcwire.com/hpcwire/2011-12-07/nvidia_eyes_post-cuda_era_of_gpu_computing.html}
\hyperref{}{http://www.hpcwire.com/hpcwire/2012-06-20/openacc_group_reports_expanding_support_for_accelerator_programming_standard.html}

But the real end game for OpenACC supporters is for the directives to be incorporated into the OpenMP standard.  Since OpenACC was derived from work done within the OpenMP Working Group on Accelerators,

\subsubsection{AMD Accelerated Parallel Processing (APP) SDK}
formerly ATI Stream

\hyperref[AMD 1]{http://developer.amd.com/sdks/AMDAPPSDK/Pages/default.aspx}

\hyperref[AMD 2]{http://www.amd.com/us/products/technologies/amd-app/Pages/eyespeed.aspx}










\section{Current advances in NVIDIA and AMD Architectures}
today we have two viable and
competitive product lines, Nvidia and Advanced
Micro Devices (AMD) GPUs, with support for a
wide range of programming languages.

GPUs on super-computers

\subsection{NVIDIA}
\subsubsection{Tesla}
\subsubsection{Fermi}
\subsubsection{Kepler}

\subsection{AMD}
\subsubsection{APU}
\subsubsection{GPUs}
multicore x86

\subsection{Intel}
\subsubsection{Intel SDK for OpenCL Applications 2012}

Intel's upcoming Many Integrated Core (MIC) coprocessor, Intel MIC
