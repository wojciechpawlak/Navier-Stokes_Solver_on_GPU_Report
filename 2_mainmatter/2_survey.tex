\chapter{Survey of GPU programming}

For the exploitation of the high performance of GPUs, codes must express sufficient fine-grained parallelism, minimize GPU–CPU data transfer, and achieve coalesced memory access. One option for writing the GPU code is to do so directly in CUDA [1] or OpenCL [27]. For a large Fortran code written well before the existence of GPUs, this entails a massive effort to rewrite, debug, and maintain a separate branch of the code. An alternative to performing such a monolithic code rewrite is to follow the ‘accelerator design’, as so called by Cohen and Molemaker, of porting bottleneck loops or subroutines in isolation, with memory transfer calls made just before and after these bottleneck loops or subroutines. Although this allows for the possibility of an incremental porting effort, it suffers the drawback of introducing the crippling bottleneck of a large amount of data transfer across the system bus, which has at least an order of magnitude lower bandwidth than that of the internal GPU memory, and thus severely restricts the possible gain in performance when porting

Heterogeneous: Developers leverage AMD GPUs and CPUs for optimal application performance and user experience

Industry Standards:OpenCL™ and DirectCompute11enable cross-platform development

High performance: Massively parallel, programmable GPU architecture enables superior performance and power efficiency

With OpenCL

Leverage CPUs and GPUs to accelerate parallel computation
Get dramatic speedups for computationally intensiveapplications
Write accelerated portablecode across different devices and architectures


AMD APP Acceleration 


\subsection{Automation of porting to GPU process}

\hyperref[AMD]{http://stackoverflow.com/questions/1126989/what-future-does-the-gpu-have-in-computing}


\section{OpenCL}

OpenCL (Open Computing Language) is an open
standard defined by Khronos Group [16]. In contrast
to the CUDA library supported mainly by NVIDIA
it is a vendor-independent framework that enables
the programmer to develop software that can be executed
on heterogeneous platforms consisting of CPUs,
GPUs and potentially other processing units like FPGAs.

22Kernel
Basic unit of executable code -similar to a C function
Data-parallel or task-parallelProgram
Collection of kernels and other functions
Analogous to a dynamic libraryApplications queue kernel execution instances
Queued in-order
Executed in-order or out-of-order

Pipeline - table:
find platform
find device
create context and queue
build program
write device buffers
execute kernel in range
read device buffers


\subsection{Differences to CUDA}

\section{Previous research}



\section{Recent developments in CUDA and OpenCL}
\subsection{OpenCL}

What applications use OpenCL GPU-acceleration?
OpenCL in Photoshop CS6
WinZip 16.5

OpenCL Studio

\hyperref[OpenCLStudio]{http://www.youtube.com/user/OpenCLStudio}

\subsection{CUDA}

\subsection{Other Technologies}
\subsubsection{C++ AMP (C++ Accelerated Massive Parallelism)}

\hyperref[C++ AMP MSDN]{http://msdn.microsoft.com/en-us/library/hh265137}

\subsubsection{OpenACC}
Directives like OpenMP for multicore CPU programming

\hyperref[OpenACC]{http://openacc.org/}

\subsubsection{AMD Accelerated Parallel Processing (APP) SDK}
formerly ATI Stream

\hyperref[AMD 1]{http://developer.amd.com/sdks/AMDAPPSDK/Pages/default.aspx}

\hyperref[AMD 2]{http://www.amd.com/us/products/technologies/amd-app/Pages/eyespeed.aspx}

\section{Current advances in NVIDIA and AMD Architectures}
today we have two viable and
competitive product lines, Nvidia and Advanced
Micro Devices (AMD) GPUs, with support for a
wide range of programming languages.

GPUs on super-computers

\subsection{NVIDIA}
\subsubsection{Tesla}
\subsubsection{Fermi}
\subsubsection{Kepler}

\subsection{AMD}
\subsubsection{APU}

\subsection{Intel}
\subsubsection{Intel SDK for OpenCL Applications 2012}
